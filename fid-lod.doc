<h1 id="dezentral-offen-vernetzt---überlegungen-zum-aufbau-eines-lod-basierten-fid-fachinformationssystems">Dezentral, offen, vernetzt - Überlegungen zum Aufbau eines LOD-basierten FID-Fachinformationssystems</h1>
<h2 id="english">English:</h2>
<p>Title: Decentral, open, cross-linked - reflections on building a sustainable FID metadata infrastructure</p>
<p>Keywords: Linked Open Data, libraries, metadata infrastructure, science</p>
<p>Abstract:</p>
<p>This article reflects the <a href="http://www.dfg.de/formulare/12_102/12_102_de.pdf">&quot;Richtlinien für das DFG geförderte System der Fachinformationsdienste für die Wissenschaft&quot;</a> and shows how Linked Open Data (LOD) can help with rebuilding the Sondersammelgebiete (SSG) to Fachinformationsführer (FID). In particular, the aspect of (meta-)data infrastructure is discussed. The thesis of this article is that LOD is predestined to build the base of a sustainable metadata infrastructure for science.</p>
<p>Authors:</p>
<p><a href="http://lobid.org/person/pc">Pascal Christoph</a> and <a href="http://lobid.org/person/ap">Adrian Pohl</a> Jülicher Str. 6 D-50674 Cologne<br />E-Mail: christoph@hbz-nrw.de<br />E-Mail: pohl@hbz-nrw.de</p>
<h2 id="deutsch">Deutsch:</h2>
<p>Schlüsselwörter: Linked Open Data, Fachinformationsdienste , Metadateninfrastruktur, Wissenschaft</p>
<p>Abstract:</p>
<p>Dieser Artikel reflektiert die <a href="http://www.dfg.de/formulare/12_102/12_102_de.pdf">&quot;Richtlinien für das DFG geförderte System der Fachinformationsdienste für die Wissenschaft&quot;</a> und zeigt dabei auf, wie Linked Open Data (LOD) beim Umbau der Sondersammelgebiete (SSG) zu Fachinformationsdiensten (FID) helfen kann. Es wird dabei insbesondere auf den Aspekt (Meta-)Dateninfrastruktur eingegangen. Die These dieses Artikels ist, dass LOD prädestiniert ist, einen wichtigen Eckpfeiler einer nachhaltigen Metadateninfrastruktur für die Wissenschaft zu bilden.</p>
<p>Pascal Christoph kennt ViFas und SSGs aus seiner Arbeit von 2008-2011 am Hochschulbibliothekszentrum des Landes Nordrhein-Westfalen (<a href="http://www.hbz-nrw.de/">hbz</a>) als technischer Umsetzer des Projekts <a href="http://de.wikipedia.org/wiki/Vascoda">&quot;vascoda&quot;</a>. Seit 2010 arbeitet er am Linked Open Data Dienst <a href="http://lobid.org">&quot;lobid.org&quot;</a> des hbz .</p>
<p>Adrian Pohl arbeitet seit 2008 im Hochschulbibliothekszentrum des Landes Nordrhein-Westfalen (hbz). Sein Fokus liegt auf dem Bereich Linked Open Library Data und dabei insbesondere auf dem Aufbau und der Pflege des LOD-Service lobid.org. Seit Juni 2010 ist Adrian Koordinator der OKFN Working Group on Open Bibliographic Data.</p>
<h2 id="inhaltsverzeichnis">Inhaltsverzeichnis</h2>
<ol style="list-style-type: decimal">
<li><a href="#einführung">Einführung</a></li>
<li><a href="#lod">Was ist Linked Open Data?</a><br /> 2.1 <a href="#grundlegendes">Offene Daten als grundlegende Anforderung</a><br /> 2.2 <a href="#ld">Linked Data - Best Practices</a><br /></li>
<li><a href="#vascoda">Erfahrungen aus dem vascoda-Projekt</a></li>
<li><a href="#cooperare">Cooperare necesse est</a></li>
<li><a href="#aufgabenumsetzung">Aufgabenumsetzung</a><br /> 5.1 <a href="#metadatenmapping">Metadatenmapping, Datentransformation und automatische Datenanreicherung</a><br /> 5.2 <a href="#aufbau">Aufbau von Rechercheindizes und Web-APIs</a><br /> 5.3 <a href="#hubs">Hubs zur intellektuellen Datenanreicherung</a><br /> 5.4 <a href="#flexibel">Flexible Arbeitsteilung</a><br /></li>
<li><a href="#fazit">Fazit</a></li>
<li><a href="#referenzen">Referenzen</a></li>
</ol>
<h2 id="einführung"><a name="einführung"></a>Einführung</h2>
<p>Die <a href="http://www.dfg.de/formulare/12_102/12_102_de.pdf">&quot;Richtlinien für das DFG geförderte System der Fachinformationsdienste für die Wissenschaft&quot;</a> der Deutschen Forschungsgemeinschaft (DFG) und das damit verbundene Förderprogramm haben den Aufbau sogenannter &quot;Fachinformationsdienste für die Wissenschaft&quot; (FID) zum Ziel. Diese FIDs sollen die bestehenden Strukturen der Sondersammelgebiete (SSG) und Virtuellen Fachbibliotheken (ViFa) zusammenführen und schließlich ersetzen. Diese von der DFG geförderten Strukturen dienen seit jeher dem Zweck der wissenschaftlichen Informationsversorgung. Dementsprechend haben die FIDs zukünftig die Aufgabe, die Informationsbedürfnisse von Fachwissenschaftlerinnen und Fachwissenschaftlern zu befriedigen. Die DFG verbindet mit &quot;der Verabschiedung des neu ausgerichteten Förderprogramms ... die Hoffung, dass die 'Fachinformationsdienste für die Wissenschaft' als ein flexibles und zukunftsfähiges System der Informationsversorgung der Wissenschaft dienen können&quot;.<br /><em>DFG: Fachinformationsdienste für die Wissenschaft. Richtlinien für das DFG geförderte System der Fachinformationsdienste für die Wissenschaft. 2013, S. 4.</em></p>
<p>Die Grundannahmen dieses Artikels sind:</p>
<ol style="list-style-type: decimal">
<li>Wissenschaftler wollen auf einfache Weise über neue für sie relevante Veröffentlichungen erfahren.<br /></li>
<li>Wissenschaftler wollen möglichst einfachen Zugriff auf alle für sie relevanten Informationen.<br /></li>
<li>Wissenschaftler wollen die von ihnen erzeugten Texte und Daten wiederum für alle Interessierten auffindbar machen.<br /></li>
<li>Die in 1. - 3. genannten Prozesse der Informationsversorgung geschehen idealerweise über das Internet.</li>
</ol>
<p>Die These dieses Artikels ist, dass Linked Open Data (LOD) einen wichtigen Beitrag dazu liefert, den Anforderungen eines flexiblen und zukunftsfähigen Systems der Informationsversorgung gerecht zu werden.<sup><a href="#fn1" class="footnoteRef" id="fnref1">1</a></sup> Im folgenden werden zunächst knapp die Best Practices von Linked Open Data vermittelt (Abschnitt 2). Sodann werden Erfahrungen dem vascoda-Projekt geschildert und Probleme des Projekts aufgezeigt, die mit einem LOD-Ansatz hätten vermieden werden können (Abschnitt 3). In Abschnitt 4 werden Entwicklungs-, Kommunikations- und Organisationsprinzipien behandelt, die in der LOD-Gemeinschaft gepflegt werden und den kollaborativen Aufbau einer nachhaltigen und flexiblen Informationsinfrastruktur begünstigen. Abschnitt 6 setzt sich mit konkreten Bereichen im Kontext des Metadatenmanagements auseinander, in denen eine Kooperation besonders sinnvoll ist. {...}</p>
<p>Konkret nennen die Richtlinien der DFG folgende Kernaufgaben von Fachinformationsdiensten:</p>
<p>&quot; Die Fachinformationsdienste gewährleisten eine optimale Versorgung - durch die überregionale Bereitstellung und Archivierung relevanter gedruckter und digitaler Medien und Fachinformationen, - durch den Aufbau und die Pflege komfortabler Nachweis- und Recherchesysteme, die technisch auf dem neuesten Stand gehalten werden und - durch vorausschauendes Engagement in der Entwicklung allgemeiner und fachspezifischer Informationsdienstleistungen (darunter beispielsweise Rechercheaufträge, Beratungsleistungen, Digitalisierung mit Mehrwertdiensten, Tiefenerschließung).&quot;<br /><em>Fachinformationsdienste für die Wissenschaft. Richtlinien für das DFG geförderte System der Fachinformationsdienste für die Wissenschaft. 2013, S. 5-6 .</em></p>
<p>Dieser Text befasst sich nur mit der Umsetzung der zweiten genannte Kernaufgabe &quot;Aufbau und die Pflege komfortabler Nachweis- und Recherchesysteme&quot; und den damit verbundenen Prozessen der Datenaggregation und des Datenmanagements. Auch wenn LOD in den beiden anderen genannten Aufgabengebieten wohl einige Vorteile mit sich bringen kann, weil Metadate auch bei der Auswahl von Ressourcen bzw. deren Archivierung eine wichtige Rolle spielen - den Autoren fehlt in diesen Bereichen schlicht die nötige Expertise, so dass dieser Beitrag dazu schweigt.</p>
<h2 id="was-ist-linked-open-data"><a name="lod"></a>Was ist Linked Open Data?</h2>
<p>Die grundlegende Idee von LOD ist Offenheit. &quot;Offenheit&quot; gestaltet sich hierbei in mehreren Dimensionen:</p>
<ul>
<li>Die <em>Lizenz</em> ist offen, d.h. die Daten dürfen von jedem verändert und nachgenutzt werden.</li>
<li>Das <em>Datenmodell</em> ist offen, d.h. es nicht nicht starr, sondern kann flexibel erweitert und ergänzt werden.</li>
<li>Die zugrundeliegenden <em>Standards</em> sind offen. Ihre Entwicklung wird vom World Wide Web Consortium (<a href="http://w3c.org">W3C</a>) koordiniert.</li>
<li>Die <em>Software</em> rund um LOD ist - im Vergleich zu anderen Bereichen - bestimmt von einer großen Zahl an Open-Source-Entwicklungen.<sup><a href="#fn2" class="footnoteRef" id="fnref2">2</a></sup></li>
<li>Die <em>Teilnahme</em> ist offen für jeden, da LOD - wie das World Wide Web - dezentral ist. Es gilt das Motto: &quot;Anybody can say anything about anything&quot;.<sup><a href="#fn3" class="footnoteRef" id="fnref3">3</a></sup></li>
</ul>
<p>Eine knappe, eher technische Beschreibung von LOD lautet:</p>
<blockquote>
<p>&quot;Linked Open Data sind offene Daten (Open Data), die gemäß Linked-Data-Prinzipien (Linked Data) unter Nutzung der entsprechenden offenen W3C-Standards bereitgestellt werden. Während Open Data keine Datenformate vorgibt, solange es sich um offen dokumentierte Formate handelt, geht es bei Linked Data um die Etablierung von Best Practices für die Integration von Daten in das WWW auf Basis von Standards des World Wide Web Consortium (W3C). Die vier von Tim Berners-Lee<sup><a href="#fn4" class="footnoteRef" id="fnref4">4</a></sup> formulierten Linked-Data-Prinzipien lauten:</p>
<ol style="list-style-type: decimal">
<li>Benutze URIs als Namen für Dinge.</li>
<li>Benutze HTTP-URIs, damit Menschen die Namen nachschlagen können.</li>
<li>Wenn jemand eine URI nachschlägt, liefere nützliche Informationen auf Basis der Standards (RDF, SPARQL).</li>
<li>Verlinke zu anderen URIs, so dass mehr Dinge entdeckt werden können.</li>
</ol>
<p>Linked Data baut also auf den bestehenden Web-Standards Uniform Resource Identifiers (URI) und Hypertext Transfer Protocol (HTTP) auf und ergänzt diese durch das Datenmodell RDF (Resource Description Framework) zur Repräsentation von Information, SPARQL (SPARQL Protocol And RDF Query Language)zu Abfrage von RDF-Daten und RDFS sowie OWL (Web Ontology Language) zur Schaffung von Vokabularen/Ontologien.&quot;<br /><em>DINI-AG-KIM: LOD-Glossar. 2013.</em></p>
</blockquote>
<h3 id="offene-daten-als-grundlegende-anforderung"><a name="grundlegendes"></a>Offene Daten als grundlegende Anforderung</h3>
<p>Grundlage eines jeden Fachinformationssystems sind Aufbau und Pflege des <em>Bestand</em>s, um Zugriff auf relevante Ressourcen ermöglichen zu können sowie die <em>Metadaten</em> für Nachweis- und Recherchesyteme, so dass eine Ressource überhaupt aufgefunden werden kann. Um technisch in der Lage zu sein, optimale Recherche- und Nachweissysteme zu bauen, sollte der Zugriff auf die nötigen Metadaten möglichst einfach und reibungslos vor sich gehen. Idealerweise stellen Metadatenproduzenten ihre Daten unter einer offenen Lizenz<sup><a href="#fn5" class="footnoteRef" id="fnref5">5</a></sup></p>
<p>In Deutschland haben die Deutsche Nationalbibliothek (DNB) und die deutschen Bibliotheksverbünde haben bereits mit der Freigabe von Daten begonnen.<sup><a href="#fn6" class="footnoteRef" id="fnref6">6</a></sup> Der Bibliotheksverbund Bayern (BVB) und der Kooperative Bibliotheksverbund Berlin-Brandenburg (KOBV) sowie das hbz stellen ihre Daten sowohl als MARC oder MAB und auch als LOD bereit und bieten darüber hinaus regelmäßige Aktualisierungen an. Die DNB bietet den größten Teil ihrer Daten unter einer offenen Lizenz an mit einjähriger <a href="https://en.wikipedia.org/wiki/Moving_wall">&quot;Moving Wall&quot;</a>. Für bestimmte Fächer lässt sich damit u. U. bereits ein guter FID-Recherchedienst aufbauen. Dabei sind Monographiedaten ganz gut abgedeckt, oft fehlen aber Artikelmetadaten und graue Literatur. Damit das &quot;web of data&quot; Realität wird, müssen weitere Daten geöffnet werden. Und dies geschieht am Besten dort, wo diese Daten originär anfallen.</p>
<p>Möglichst viele Verlage, Ersteller von Fachbibliographien, die FIDs selbst und andere Metadatenprovider sollten dazu gebracht werden, ihre Metadaten sowie andere für die Recherche nützliche Daten (wie z. B. Inhaltsverzeichnisse und Abstracts) als Open Data unter CC0 zur Verfügung zu stellen. Ein weiterer wichtiger Schritt bestünde in der Überlassung einer kompletten Kopie der digitalen Veröffentlichung, z.B. um diese in Volltextsuchmaschinen zu indexieren oder um sie zur automatischen Anreicherung der Metadaten (Klassifizierung, Verschlagwortung usw.) zu nutzen oder/und um die Ressource langzeitverfügbar zu machen. Die weitere Verbreitung von Open Access wäre auch für diesen Zweck sehr erfreulich, ja sogar notwendig: Gerade für Wissenschaftler (und also für FIDs) interessant sind Hochschulschriften und Hochschulabschlussarbeiten - diese liegen leider immer noch oft nicht als Open Access vor.<sup><a href="#fn7" class="footnoteRef" id="fnref7">7</a></sup></p>
<h3 id="linked-data---best-practices"><a name="ld"></a>Linked Data - Best Practices</h3>
<p>Linked Open Data bedeutet - wie soeben ausgeführt - einerseits die offene Lizenzierung von Daten (&quot;Open Data&quot;). Andererseits bezieht sich das &quot;Linked Data&quot; in LOD bezieht auf eine Menge von Best Practices zur Datenpublikation, die auf Standards des W3C basieren.</p>
<p>LOD ist somit eng mit dem World Wide Web (WWW) verzahnt. Es baut auf den gleichen Technologien und Standards auf. Oft wird das WWW auch als &quot;web of documents&quot;, also als &quot;Netz von Dokumenten&quot;, bezeichnet. LOD hingegen kann als &quot;web of data&quot;, als &quot;Netz von Daten&quot;, bezeichnet werden. Während im WWW also Dokumente miteinander verknüpft sind, so sind im LOD-Netz Daten miteinander verknüpft. Ein wesentlicher Unterschied von LOD und den Hyperlinks zwischen HTML-Dokumenten (also den &quot;Links&quot; in z.B. Webseiten) ist die Art der Verknüpfung: Das LOD Paradigma erzwingt bedeutungsvolle Beziehungen von Subjekt (also das, was verlinkt wird) und dem Objekt (also das, wohin verlinkt wird). Das ist im Vergleich zu bibliothekarischen Datenbanken nichts Neues, denn dort werden stets Aussagen gemacht wie &quot;Buch X hat den Autor Y&quot; und &quot;Autor Y wurde geboren im Jahr Z&quot;.</p>
<p>Anders als bei Datenbanken, die im &quot;deep web&quot; versteckt sind, kann bei LOD jede zum gemeinsamen Datenpool etwas hinzufügen - denn, wer eine Webseite anlegen kann, kann auch LOD herstellen und Informationen dem &quot;web of data&quot; hinzufügen. So wächst die LOD-Cloud, und zwar vor allem durch Verlinkung. Ein Beispiel: Wissenschaftler A schreibt einen Artikel B der Artikel C referenziert und Wissenschaftler D widerspricht. Diese Referenzen sind nichts anderes als Verlinkungen zwischen A und B, B und C und C und D, jeweils mit einer spezifizierten semantischen Relation. Werden diese Beziehungen in dem Artikel als LOD hinterlegt<sup><a href="#fn8" class="footnoteRef" id="fnref8">8</a></sup> und erhält der Artikel einen HTTP-URI und ist also Teil des WWW, dann ist damit die LOD Datenbank gewachsen. <sup><a href="#fn9" class="footnoteRef" id="fnref9">9</a></sup>.</p>
<p>Auf Basis einer großen Menge dezentral gepflegter, untereinander vernetzter Daten sind Abfragen wie &quot;gib mir alle Dokumente, die von Personen geschrieben wurden, die im 16 Jhd. geboren sind und mit 'Chemie' verschlagwortet sind&quot; einfach realisierbar. Dabei ist es ausreichend, einem lediglich zwei Aussagen (&quot;RDF-Tripel&quot;) über ein Dokument hinzuzufügen: Der eine Eintrag verknüpft das Dokument mit einer LOD fähigen Schlagwortdatei, z.B. der Dewey Decimal Classification oder der GND, der zweite Eintrag verknüpft das Dokument mit der Personen ID. Alle weiteren Daten (multilinguale natürlichsprachige Bezeichnung des Schlagwortes, Lebensdaten des Autors usw.) müssen nicht in das Dokument mitaufgenommen werden, sondern sind, da sie im WWW bereits vorliegen, von dort automatisiert abrufbar. In einem LOD-<a href="https://de.wikipedia.org/wiki/Graph_%28Graphentheorie%29">&quot;Graphen&quot;</a> gibt es per se keinen von vornherein abgeschlossenen Datensatz, da alles mit allem verknüpft sein kann und somit weder Anfang noch Ende hat. Datenproduzenten und -konsumenten müssen selbst entscheiden, wo ein Datensatz anfangen und wo er sinnvollerweise aufhören soll, welche Daten als vertrauenswürdig angesehen werden und welche vielleicht z.B. Spam sind.<sup><a href="#fn10" class="footnoteRef" id="fnref10">10</a></sup> Das Datenmodell von LOD lässt also unbegrenzte neue Aussagen zu, während bei herkömmlichen Austauschformaten die maximale Größe eines Titeldatensatzes festgelegt ist<sup><a href="#fn11" class="footnoteRef" id="fnref11">11</a></sup>. Für LOD gibt es auch keine Beschränkung der möglichen Informationsdichte eines Metadatensatzes, also dessen, was in den herkömmlichen Datenmodellen die Metadatenfelder sind. Zwar lassen sich auch den überkommenen, für Magentbänder optimierten Datenstrukturen aus den 1960er/1970er Jahren neue Felder teilweise durch mühselige Standardisierungsprozesse hinzufügen und teilweise auch beliebig und lokal definieren (was zu Inkompatibilität der Kataloge führt), doch sind diese &quot;Format&quot;-Beschreibungen nicht offen und funktionieren deshalb im besten Fall nur in ihrem begrenzten System: der Bibliothekswelt. Die Metadaten der Bibliothekswelt sind aber viel zu wertvoll, d. h. nützlich, um sie nicht in das WWW zu integrieren. Sie sind dafür auch besonders gut geeignet: Tatsächlich existiert bereits in den älteren Austauschformaten MAB/MARC/PICA eine große Anzahl von Verlinkungen (zwischen Titeldatensätzen, zwischen Titel- und Normdatensätzen) gerade im deutschsprachigen Raum.</p>
<p>So, wie das WWW dezentral aufgebaut ist und es viele verschiedene Webseitenbetreiber gibt - wenn sich auch immmer wieder einige zentrale Dienste herausbilden wie aktuell etwa Google, Facebook, Wikipedia oder Amazon), so liegen auch die verlinkten offenen Daten verteilt im Netz. Dieses LOD wird von verschiedenen Interessenten aggregiert und integriert, sei es um in eigenen internen Datenbanken &quot;zu verschwinden&quot;, um neue Webanwendungen herzustellen oder/und um wiederum als LOD veröffentlicht zu werden. Im letzteren Fall wurde den ursprünglichen Daten neue Daten hinzugefügt, die wiederum re-konsumiert werden können.<sup><a href="#fn12" class="footnoteRef" id="fnref12">12</a></sup> So kann z.B. die DBpedia (also die LOD-Variante der Wikipedia) den auf sie zeigenden Links folgen und die eigenen Daten mit z.B. Metadaten aus Bibliothekskatalogen anreichern.<sup><a href="#fn13" class="footnoteRef" id="fnref13">13</a></sup>. Dies eröffnet eine interessante Perspektive für Bibliotheken: Wenn diese Daten - z. B. über Wikidata - in die Wikipedia gelangen und dort die Verfügbarkeit einer referenzierten Ressource in den (durch die IP des Nutzers ermittelte) nächstgelegenen Bibliotheken angezeigt wird.</p>
<h2 id="erfahrungen-aus-dem-vascoda-projekt"><a name="vascoda"></a>Erfahrungen aus dem vascoda-Projekt</h2>
<p>Von 2008 bis Ende 2010 war der Autor Pascal Christoph beim hbz mitverantwortlich für Datentransformation und Suchmaschinenadministration für vascoda. Für das vascoda-Portal wurden Daten aus mehr als 40 verschiedenen Quellen (SSGs, ViFas, Fachportalen und auch Verbunddatenbanken) in verschiedensten Formaten für die Suchmaschine aufbereitet. Auch wenn in den DFG- Richtlinien eine Portallösung für FIDs nicht als zwingend vorausgesetzt wird, ist es sinnvoll, an dieser Stelle knapp auf die Erfahrungen mit vascoda, vor allem dem vascoda-Portal, einzugehen. Mit der Anwendung der LOD-Best- Practices durch FIDs wäre die Gefahr der Wiederholung vieler Probleme von vascoda nämlich per definitionem von vornherein ausgeschlossen. Einige konkrete Probleme, die sich durch einen LOD-Einsatz vermeiden lassen, seien im Folgenden genannt.</p>
<ul>
<li>Oftmals wurde vascoda als bloße Backlink-Maschine zu den jeweils eigenen Portalen gesehen, d. h. viele wichtige Metadaten (u. a. Bestandsdaten) wurden vascoda vorenthalten, sodass die an Bestandsnachweisen interessierte Benutzerin gezwungen war, in das jeweilige fachspezifische Portal zu wechseln. Solche unnötigen Portalbrüche werden aber als verwirrend und bestenfalls als umständlich empfunden. Ebenso durften teilweise Schlagwörter zwar in vascoda indexiert und also gesucht, nicht aber zur Anzeige gebracht werden. Benutzer, die die eingegebenen Suchwörter nicht auch in der Trefferliste wiederfinden, begegnen den Ergebnissen eher skeptisch, da sie an das Hervorheben von Suchbegriffen in der Kurztrefferanzeige gewöhnt sind, das in fast allen Internetsuchmaschinen Verwendung findet. LOD setzt den Willen zur Bereitstellung eigener Daten für eine freie Nutzung u.a. durch die offene Lizenzierung der Daten voraus. Dadurch wird Datenaggreagatoren größtmögliche Flexibilität bei der Einbindung der Daten gegeben.<sup><a href="#fn14" class="footnoteRef" id="fnref14">14</a></sup>.</li>
<li>Durch die Konzentration auf das Portal als Mensch-Maschinenschnittstelle wurden Maschine-Maschineschnittstellen vernachlässigt. Und doch war das Interesse an den Daten groß genug, um Vascoda in das <a href="https://en.wikipedia.org/wiki/WorldWideScience">&quot;WorldWideScience&quot;</a>-Portal einzubinden. Dies geschah mittels sog. HTML-Scrapings<sup><a href="#fn15" class="footnoteRef" id="fnref15">15</a></sup> Erst am Ende des Projekts wurde die Einbindung einer Schnittstelle in die USB Köln testweise realisiert. Im LOD Paradigma hingegen sind die Daten immer schon maschinenlesbar. D.h. nicht, dass sie bereits per se eine Schnittstelle sind, doch liegen die Daten immer strukturiert und maschinenlesbar vor, sodass die Einbettung der Daten in andere Applikationen sehr viel einfacher und stabiler ist.</li>
<li>Die Softwareentwicklung rund um vascoda geschah nicht als Open Source. Dadurch konnte sich keine Technikergemeinschaft (&quot;Community&quot;) rund um das Projekt aufbauen, um eine Nachhaltigkeit war damit nicht gegeben. Ganz anders verhält es sich bei Werkzeugen, die im Umkreis von LOD entstehen, sei es <a href="http://culturegraph.org">culturegraph.org</a>, die LOD-Graphdatenbanken wie Virtuoso, 4store usw., LOD-kompatible Suchmaschinen wie elasticsearch, Datenanreicherungswerkzeuge wie SILK, Datenaustauschplattformen wie datahub oder die Werkzeuge der von der DFG geförderten <a href="http://aksw.org">AKSW in Leipzig</a> et cetera. Natürlich gibt es auch einige proprietäre, Closed Source Software, doch existieren immer auch leistungsfähige Open-Source-Software-Alternativen, die sogar meist kostenlos verteilt werden, dafür aber auch meist mit kostenpflichtigen Serviceangeboten daherkommen.</li>
<li>Anders als im vascoda-Projekt, anders als wohl generell früher im Umfeld von bibliothekarischen Institutionen, begünstigt LOD eine weniger hierarchisch und zentralistisch &quot;top-down&quot; strukturierte Arbeitsweise. Es eignet sich hervorragend als Basis zum Aufbau eine verteilten Community mit flachen Hierarchien. Ein gutes Beispiel liefert die Entstehung eines gemeinsamen Metadatenschemas für bibliographische Daten im deutschsprachigen Raum: Den verschiedenen LOD-Produzenten (DNB, hbz, BVB, Hebis, zbw u.a.) wurde zu keinem Zeitpunkt ein gemeinsames Metdatenschema oktroyiert, sondern es hat sich durch &quot;Best Practices&quot;-Konventionen herausgebildet, die mittlerweile - organisiert innerhalb der DINI-AG-KIM-Gruppe &quot;Titeldaten&quot; - in eine erste Version der <a href="https://wiki.dnb.de/pages/viewpage.action?pageId=68060017">&quot;Empfehlung für die RDF-Repräsentation bibliografischer Daten&quot;</a> gemündet sind.</li>
<li>Auch hat sich im LOD-Bereich eine Arbeitsweise etabliert, die es erlaubt, auf neue Entwicklungen und Anforderungen flexibel zu reagieren. Diese Arbeitsweise ist vergleichbar mit der <a href="https://de.wikipedia.org/wiki/Agile_Softwareentwicklung">&quot;agilen Softwareentwicklung&quot;</a>, deren Motto des &quot;release early, release often&quot; ein ständiges Testen und Anpassen von Software an konkrete Bedürfnisse erlaubt. Komplizierte Organisationsprozesse und bürokratische Aufwände können so vermieden werden bzw. stehen der Arbeitskette nicht unbedingt im Weg - die Abhängigkeit von Entscheidungen auf oberer Ebene (z.B. wie das Datenapplikationsprofil aussehen soll) verhindern nicht, dass Daten bereits transformiert werden und über Nachweissysteme recherchierbar sind. Damit sind evolutionäre, oder auch &quot;iterative&quot;, Anpassungen möglichen - es ist nicht notwendig das &quot;perfekte&quot; Datenapplikationsprofil zu erstellen. Diese Arbeitsweisen, die nicht nur - aber auch - im LOD-Umfeld vorherrschen, sind somit höchst flexibel.</li>
</ul>
<p>Wir haben in diesem und dem letzten beiden Kapiteln gesehen: LOD unterstützt auf der einen Seite direkt Aufbau und Pflege einer Informationsinfrastruktur - durch den dezentralen Ansatz, die Flexibilität des Datenmodells und die offene Lizenzierung von Daten. Auf der anderen Seite fördert LOD indirekt den Aufbau einer solchen Infrastruktur , weil etwa bestimmte Arbeitsweisen (agile Entwicklung), ein offener Austausch und Kooperation oder die Nutzung von Open Source Software im LOD-Kontext weit verbreitet sind. Da im Vergleich zu den konkreten Technologien die &quot;weichen Faktoren&quot; der Kommunikation und Organisation von grundlegenderer Wichtigkeit sind, wird im folgenden zunächst auf diese eingegangen ehe die konkrete Aufgabenumsetzung unter Nutzung von LOD angesprochen wird.</p>
<h2 id="cooperare-necesse-es"><a name="cooperare"></a>Cooperare necesse es</h2>
<p>Die umfangreichen und teilweise komplexen Aufgaben, die FIDs zu bewältigen haben, und die Knappheit der dafür zur Verfügung stehenden Ressourcen legen eine Kooperation der betroffenen Einrichtungen nahe - nicht umsonst weist die DFG auf das Potential der Bündelung von Querschnittsaufgaben in Kompetenzzentren hin. Gute Bedingungen herzustellen für die Herstellung und Pflege eines so nachhaltigen wie innovativen Systems der Informationsversorgung ist allerdings keine leichte Aufgabe. Konkrete Technologien spielen beim Aufbau eines solchen Systems eine untergeordnete Rolle, sie können seine Entstehung allenfalls unterstützen. Wichtiger sind bestimmte Formen der Zusammenarbeit, der Kommunikation, des Teilens von Erfahrungen und Wissen. Als pointierte Darstellung der wichtigen Aspekte sei an dieser Stelle der Entwurf eines Manifests zitiert, das zur Beförderung einer entsprechenden kollaborativen Arbeitsweise für den Aufau einer zukunftsfähigen, innovativen und durch öffentliche Einrichtungen kontrollierten Bibliotheks-IT-Infrastruktur verfasst wurde: &quot;</p>
<blockquote>
<h1>Libraries Empowerment Manifesto</h1>
</blockquote>
<blockquote>
<p>We support the formation and development of an international library infrastructure that is: * <em>future-proof</em>: it supports the development of sustainable solutions; * <em>progressive</em>: it enables rapid development and quick adaptation to upcoming challenges; * <em>empowering</em>: it empowers libraries to control to the maximum the infrastructure underlying their services for collection, indexing and dissemination of published knowledge.</p>
<p>In order to reach the goal of a future-proof, progressive infrastructure that empowers libraries to control their future to the maximum, we endorse the following principles:</p>
<ul>
<li><em>Openness</em>. To the extent possible, we share our data, content, tools and ideas on the web, according to the requirements of the <a href="http://www.gnu.org/philosophy/free-sw.html">Free Software Definition</a> and the <a href="http://opendefinition.org/">Open Definition</a> and the best practices of the wider web community.</li>
<li><em>Transparency</em>. Rules of conduct, project plans, minutes, plans for new features, and other artifacts are open, public, and easily accessible</li>
<li><em>Inclusion</em>. Our projects are open to all; we provide the same opportunity to all. Everyone participates with the same rules; there are no rules to exclude any potential contributors which include, of course, direct competitors in the marketplace.</li>
<li><em>Meritocracy</em>. The more you contribute the more responsibility you will earn. Leadership roles are also merit-based and earned by peer acclaim.</li>
<li><em>Reuse</em>. We actively seek for solutions others have developed for a specific problem and are happy to reuse and adapt them for our context.</li>
<li><em>Credit</em>. We <a href="http://blog.ninapaley.com/2011/06/27/credit-is-due/">give credit where credit is due</a>.</li>
</ul>
<p>We know that libraries, archives, museums, and related organizations can't change from one day to the next. Nonetheless, we seek to organize our work according to these principles, even if we might start imperfectly and/or only within parts of the organization.</p>
</blockquote>
<p>Das Manifest ist auf Englisch verfasst, weil Kollaboration an Landesgrenzen nicht Halt macht und Erfahrungen und Lösungen, die auch für nicht-deutsche Institutionen von Nutzen sein könnten, im besten Fall auch diesen zugänglich gemacht werden sollten. Wie bereits angemerkt handelt es sich bei dem Manifest um einen Entwurf. Alle Interessierten sind herzlich eingeladen, sich an der weiteren Entwicklung zu beteiligen.<sup><a href="#fn16" class="footnoteRef" id="fnref16">16</a></sup></p>
<h2 id="aufgabenumsetzung"><a name="aufgabenumsetzung"></a>Aufgabenumsetzung</h2>
<p>Den FIDs wird ziemlich freie Hand dabei gelassen, die Informationsbedürfnisse des Wissenschaftlers zu befriedigen. Das bedeutet unter anderem, dass FIDs die Wahl haben, technische Infrastrukturen selbst aufzubauen und zu pflegen oder aber lediglich als Vermittler zwischen den Dienstleistern (Datenerzeugern auf der einen, Datenverarbeiter auf der anderen Seite) aufzutreten. In den DFG-Richtlinien steht dazu im Kapitel &quot;Querschnittsaufgaben&quot;:</p>
<blockquote>
<p>&quot;Im System der Fachinformationsdienste sind für jene technisch-organisatorischen Arbeiten, die für die einzelnen Fachgebiete gleichartig durchzuführen sind und zugleich einen hohen Arbeitsaufwand und besondere Expertise erfordern, Querschnittsbereiche vorgesehen, in denen die Betreuung dieser Aufgaben gebündelt wahrgenommen wird. Dies betrifft vor allem den Umgang mit digitalen Medien. Dabei ist es ein ausdrückliches Ziel, durch die Aufgabenbündelung eine Entlastung zugunsten der fachlichen Arbeit in den einzelnen Fachinformationsdienstenzu erreichen und durch Synergieeffekte auch das Potential für Einsparungen optimal auszunutzen.&quot;<br /> <em>DFG: Fachinformationsdienste für die Wissenschaft. Richtlinien für das DFG geförderte System der Fachinformationsdienste für die Wissenschaft. S. 10 .</em></p>
</blockquote>
<p>Dieser Anstoß der DFG zur Kooperation und zum Aufbau von Kompetenzzentren für &quot;Querschnittsaufgaben&quot; ist zu begrüßen. Die Möglichkeiten zum Aufbau von Synergien sollen im folgenden näher betrachtet werden insbesondere mit Blick auf die Arbeit mit und Bereitstellung von Daten. Es geht also vor allem um folgende Aufgaben:</p>
<ul>
<li><a href="#metadatenmapping">Metadatenmapping, Datentransformation und automatische Datenanreicherung</a></li>
<li><a href="#aufbau">Aufbau von Rechercheindizes und Web-APIs</a></li>
<li><a href="#hubs">die intellektuelle Erstellung, Verbesserung und Anreicherung von Erschließungsinformationen</a></li>
</ul>
<h3 id="metadatenmapping-datentransformation-und-automatische-datenanreicherung"><a name="metadatenmapping"></a>Metadatenmapping, Datentransformation und automatische Datenanreicherung</h3>
<p>Bei jedem Dienst, der eine Recherche über aus verschiedenen Quellen aggregierte Daten ermöglicht, fallen regelmäßig und langfristig Aufgaben im Kontext von Datenaggregation, Metadatenmapping, Datentransformation und -anreicherung an. Bisher haben meist unterschiedliche Institutionen jeweils eigene Expertisen und eigene Lösungen für diese Aufgaben entwickelt. Häufig findet auch eine gegenseitige Unterstützung und Zusammenarbeit einiger Insitutionen statt, indem etwa entwickelte Software-Anwendungen weitergegeben werden. Kooperationen finden aber meist eher unter der Hand und nicht transparent im Web statt.</p>
<p>Diese Situation hat vor einiger Zeit begonnen sich zu ändern. Mittlerweile sind mächtige Werkzeuge zur Metadatentransformation als freie Software im Web verfügbar. Beispiele sind das im <a href="https://github.com/culturegraph/metafacture-core">culturegraph-Projekt entwickelte Metafacture</a> und das zentrale Tool des <a href="http://librecat.org/">LibreCat</a>, nämlich das Open-Source-Projekt <a href="https://github.com/LibreCat/Catmandu">Catmandu</a>.</p>
<p>Auch in den Transformationsprogrammen ist Modularität, und somit Flexibilität und Wiederverwendungsmöglichkeit ein zentrales Anliegen. Für Metafacture sind die für die Datentransformationen notwendigen Beschreibungen von Feldüberführungen (&quot;Mapping&quot;) in Konfigurationsdateien hinterlegt .<sup><a href="#fn17" class="footnoteRef" id="fnref17">17</a></sup> Diese Mappingdateien werden über eine Workflowdatei<sup><a href="#fn18" class="footnoteRef" id="fnref18">18</a></sup> gesteuert. Die Adaption dieser zwei Dateien erlauben es, den kompletten Transformationsprozess zu kontrollieren<sup><a href="#fn19" class="footnoteRef" id="fnref19">19</a></sup>, d.h. dass auch ohne Programmierkenntnisse Datentransformationen definiert und durchgeführt werden können.</p>
<p>Auch für die automatische Datenanreicherung gibt es freie Software, die diese Aufgabe unterstützt. Z.B. können mit dem im EU-Projekt &quot;LOD2&quot; entwickelten <a href="http://lod2.eu/Project/Silk.html">Silk</a> und auch mit <a href="http://limes.aksw.org/">Limes</a> Zusammenführungen von LOD-Daten durchgeführt werden. Das Projekt <a href="http://www.culturegraph.org">&quot;culturegraph&quot;</a> bietet ebenfalls eine Plattform für Datenzusammenführung. Dabei wird die Software <a href="https://hadoop.apache.org/">&quot;hadoop&quot;</a> eingesetzt, die auch in lobid.org für die Datenzusammenführung Verwendung findet. Synergien entstehen hier ebenfalls durch die transparente, offene Zusammenarbeit im Bereich Algorithmenentwicklung. So sind z.B. erste Algorithmen zur Berechnung von Bündeln offen publiziert.^[Siehe dazu [http://hub.culturegraph.org/statistics/alg(http://hub.culturegraph.org/statistics/alg).] Alle an automatischer bibliographsicher Datenanreicherung Interessierten können auf diese Algorithmen zugreifen und für eigene Zwecke nutzen.</p>
<h3 id="aufbau-von-rechercheindizes-und-web-apis"><a name="aufbau"></a>Aufbau von Rechercheindizes und Web-APIs</h3>
<p>Zum Aufbau von Rechercheindizes und APIs<sup><a href="#fn20" class="footnoteRef" id="fnref20">20</a></sup> eignet sich bereits vorhandene leistungsfähige Open-Source-Software wie etwa die Suchmaschinen Solr oder elasticsearch. Technische Dienstleister, auch u.a. Verbünde und Bibliotheken, können teilweise die technische Infrastruktur bereitstellen und bei deren Nutzung unterstützen. Dabei wird das gesamte Leistungsspektrum abgedeckt, von Beratung über Installation über Hosting bis zur (Weiter-)Entwicklung. Das hbz bietet beispielsweise seit Kurzem seinen Verbundkatalog über eine selbstentwickelte LOD-Web-API an.<sup><a href="#fn21" class="footnoteRef" id="fnref21">21</a></sup>. Unter dieser API, die sich sehr einfach in eigene Anwendungen über das WWW einbinden lässt, findet sich auch die GND, auf die mittels <a href="https://de.wikipedia.org/wiki/Vorschlagssuche">Vorschlagsuche</a> nach Autoren gesucht werden kann, um auf diese Weise die für die Person eindeutige GND-ID zu bekommen. Diese API steht jedem offen und kann z.B. in Katalogisierungsklienten eingebunden werden. Dadurch entstehen hohe Synergieeffekte, da diese Funktionalität prinzipiell von allen Katalogisierenden benötigt wird und aber nicht von jeder Institution neu entwickelt zu werden braucht. Die zugrundeliegende modulare Technik erlaubt es zudem, weitere Datenquellen aufzunehmen und z.B. auch dafür eine Suchvervollständigung anzubieten. Möchte ein anderer Dienstleister diese Funktionalität auf eigenen Servern selber anbieten, so kann er auf die komplette Software zugreifen, um die Dienste nachzubauen und die Software weiter(mit)zuentwickeln. Schön wäre es, wenn dabei Softwareverbesserungen auch zurückfließen. Erfahrungen mit anderen Open-Source-Projekten zeigen, dass genau dies geschieht.</p>
<h3 id="hubs-zur-intellektuellen-datenanreicherung"><a name="hubs"></a>Hubs zur intellektuellen Datenanreicherung</h3>
<p>Neben der sog. &quot;weißen Literatur&quot; gibt es &quot;graue Literatur&quot;, also alles das, was nicht durch den Buchhandel vertrieben wird. Sollte, wovon auszugehen ist, in der Auseinandersetzung mit der Fachcommunity diese auch die &quot;graue Literatur&quot; als prinzipiell interessant betrachten, so stellt sich die Frage, wie ein FID auch noch diese Ressourcen bereitstellen kann.</p>
<p>Eine Sammlung fachrelevanter Ressourcen zu betreiben erfordert eine Menge an intellektueller Arbeit. Besonders im Bereich der grauen Literatur, die teilweise gar nicht erschlossen oder nur mit unzureichenden Metadaten ausgestattet ist, ist deshalb der Einsatz von sog. <a href="https://de.wikipedia.org/wiki/Crowdsourcing">Crowdsourcing</a><sup><a href="#fn22" class="footnoteRef" id="fnref22">22</a></sup> unverzichtbar, vor allem durch die regelrechte &quot;Wissensexplosion&quot; dieser Ressourcen durch die Entwicklung des Internets. Denn der Nutzer steht nicht einfach vor einer immer größeren Informationsflut, sondern sieht sich einer mit ihm interaktiv agierenden Gemeinschaft von Gleichgesinnten gegenüber, die bereitwillig und getragen durch ebenjenes Medium &quot;Internet&quot; an der Organisation dieses Wissens mithelfen kann.<sup><a href="#fn23" class="footnoteRef" id="fnref23">23</a></sup> Wenn diese Wissensorganisation dann nach LOD Prinzipien geschieht, dann sind die Ergebnisse dieser Wissensorganisation maschinell komfortabel weiterverarbeitbar - die Informationsflut lässt sich also tatsächlich beherrschen. Die Wikimedia Foundation hat das erkannt, und mit Wikidata<sup><a href="#fn24" class="footnoteRef" id="fnref24">24</a></sup> eine Infrastruktur geschaffen, mit derer die Wikipedia nach LOD Prinzipien katalogisiert wird.<sup><a href="#fn25" class="footnoteRef" id="fnref25">25</a></sup></p>
<h3 id="flexible-arbeitsteilung"><a name="flexibel"></a>Flexible Arbeitsteilung</h3>
<p>Bei der oben beschriebenen Prozesskette kann jeder FID sich entscheiden, an welcher Stelle er die notwendigen Arbeiten selbst umsetzt und welche Leistungen als &quot;Querschnittsdienste&quot; an Dienstleister abgegeben werden. Dies betrifft Auswahl der Daten, Datentransformation und (moderierte) automatische Datenanreicherung, Veröffentlichung der Daten als LOD, die Indexierung in spezielle Datenhaltungssysteme, die Bereitstellung offener W3C Standards entsprechenden APIs über diese Datenhaltungssysteme, und die diese APIs einbindenden Nachweis- und Recherchesyteme und Portale. Durch diese Modularität und strikte Trennung von Daten, Datenhaltung und Datenanzeige<sup><a href="#fn26" class="footnoteRef" id="fnref26">26</a></sup> lassen sich die einzelnen Komponenten resp. die Dienstleister leichter austauschen. Der FID behält die Kontrolle und begibt sich weniger stark in alternativlose Abhängigkeiten. Verbesserungen der Daten bleiben erhalten und werden nicht &quot;vergessen&quot; wenn ein Portal, ein Nachweissystem oder eine API abgeschaltet oder ausgetauscht wird, da die Daten nicht zu eng an diese Komponenten gekoppelt sind: &quot;Data is stable – functions are not&quot;. Die Nachhaltigkeit bleibt auf jeden Fall in den Daten erhalten. Dadurch ist ein Lehre aus <a href="http://redmonk.com/jgovernor/2007/04/05/why-applications-are-like-fish-and-data-is-like-wine/">James Governors Bonmot &quot;Data matures like Wine, Applications like Fish&quot;</a> (&quot;Daten altern wie Wein, Anwendungen wie Fisch&quot;) gezogen.</p>
<h2 id="fazit"><a name="fazit"></a>Fazit</h2>
<p>Es wurde gezeigt, warum eine LOD Metadateninfrastruktur nachhaltig ist und wie diese zum Aufbau von FIDs-Dienstleistungen genutzt werden kann um z.B. bessere Recherche- und Nachweissysteme zu ermöglichen und die Daten in das WWW resp. in das &quot;web of data&quot; zu integrieren. Es wurde zudem gezeigt, dass große Teile dieser Infrastruktur bereits vorhanden oder in Entwicklung sind. Entscheidend für diese Metadateninfrastruktur ist, dass die Daten samt zeitnahen Updates offen lizensiert zur Verfügung stehen. Die Daten sind die Grundlage der Infrastruktur. Die Technik, also Datentransformation, die Bereitstellung der Daten als LOD und somit die Integration der Daten in das WWW, Discovery Systeme und Portale, auch die Datenhaltung an sich resp. die Archivierung usw. ist das geringere Problem - die Datenbeschaffung bleibt die größte Herausforderung. Hier können und sollten die FIDs eine entscheidende Rolle übernehmen. Der Ansatz birgt aber auch ein Risiko, da die <a href="http://www.uebertext.org/2013/04/mit-der-dfg-und-cib-nach-wordshare-und.html">DFG offensichtlich eher in proprietäre Systeme zu investieren bereit ist als in selbstenwickelte Gemeinschaftslösungen</a>.<sup><a href="#fn27" class="footnoteRef" id="fnref27">27</a></sup></p>
<p>Der Wissenschaftsrat schreibt 2011:</p>
<p>&quot;Die Integration von Katalogdaten in Metadatenbanken setzt international gültige Standards voraus. Im Bibliotheksbereich werden derzeit zwei verschiedene, nicht kompatible Ansätze praktiziert: die Zusammenführung von Katalogdaten in einer bibliographischen Datenbank, z.B. WorldCat , welche die Kataloge mehrerer tausend, auch deutscher OCLC-Mitgliedsbibliotheken umfasst, sowie die Bereitstellung von Katalogdaten in Form in das offene Web integrierter Linked Open Data . Der Wissenschaftsrat bekräftigt seine Empfehlung, dass die bibliothekarischen Verbünde im Interesse der Wissenschaft sowie ihrer eigenen Zukunftsfähigkeit rasch zu einer abgestimmten strategischen Entscheidung für einen der beiden Ansätze finden müssen. &quot;<br /><em>Wissenschaftsrat: Übergreifende Empfehlungen zu Informationsinfrastrukturen. 2011, S. 54 .</em></p>
<p>Zwar unterstützt die DFG lediglich <a href="http://dfg.de/foerderung/info_wissenschaft/archiv/2013/info_wissenschaft_13_11/index.html">die Migration der Verbünde in vorhandene Datenbanken wie WorldCat und ExLibris Alma</a><sup><a href="#fn28" class="footnoteRef" id="fnref28">28</a></sup>, doch stimmt erste die Aussage des Wissenschaftsrates nicht ganz (auch der WorldCat veröffentlicht seine Daten als Linked Data und auch <a href="http://openbiblio.net/2011/08/11/ex-libris-alma-and-open-data/">bei ExLibris gibt es Bewegung in diese Richtung</a><sup><a href="#fn29" class="footnoteRef" id="fnref29">29</a></sup> und lassen sich 2. viele zusätzliche Dienste und Dienstleistungen, wie z.B. die Integration in das WWW oder in Internetsuchmaschinen ohne Linked Data gar nicht oder nur umständlich bewerkstelligen.<sup><a href="#fn30" class="footnoteRef" id="fnref30">30</a></sup> Deshalb zeigt dieser Artikel warum, unabhängig von der Entscheidung gegen die Förderung einer selbstaufgebauten LOD-basierten Infrastruktur durch die Verbünde, die LOD-basierte Metadateninfrastruktur, die den WorldCat und ExLibris' Alma durchaus ergänzt und integriert, in die Lösung der an die FIDs gestellten Aufgaben passt.</p>
<h2 id="referenzen"><a name="referenzen"></a>Referenzen</h2>
<p>DFG (2013): Fachinformationsdienste für die Wissenschaft. Richtlinien für das DFG geförderte System der Fachinformationsdienste für die Wissenschaft. DFG-Vordruck 12.102 - 03/13. Online: <a href="http://www.dfg.de/formulare/12_102/12_102_de.pdf">http://www.dfg.de/formulare/12_102/12_102_de.pdf</a></p>
<p>Wissenschaftsrat (2011): Übergreifende Empfehlungen zu Informationsinfrastrukturen. 2011. Online: <a href="http://www.wissenschaftsrat.de/download/archiv/10466-11.pdf">http://www.wissenschaftsrat.de/download/archiv/10466-11.pdf</a></p>
<p>DFG (2013): DFG bewilligt drei Projekte zur Neuausrichtung überregionaler Informationsservices. In: Information für die Wissenschaft Nr. 11 | 15. März 2013. Online: <a href="http://dfg.de/foerderung/info_wissenschaft/archiv/2013/info_wissenschaft_13_11/index.html">http://dfg.de/foerderung/info_wissenschaft/archiv/2013/info_wissenschaft_13_11/index.html</a></p>
<p>Grant, Carl (2011): Ex Libris, Alma and Open Data . Online: <a href="http://openbiblio.net/2011/08/11/ex-libris-alma-and-open-data/">http://openbiblio.net/2011/08/11/ex-libris-alma-and-open-data/</a></p>
<p>Tochtermann, Klaus (2013): 10 Thesen zum zukünftigen Profil von wissenschaftlichen Informations-Infrastruktureinrichtungen mit überregionaler Bedeutung. Online: <a href="http://www.zbw-mediatalk.eu/2013/08/klaus-tochtermann-zehn-thesen-zum-zukunftigen-profil-von-wissenschaftlichen-informationsinfrastruktureinrichtungen-mit-uberregionaler-bedeutung/">http://www.zbw-mediatalk.eu/2013/08/klaus-tochtermann-zehn-thesen-zum-zukunftigen-profil-von-wissenschaftlichen-informationsinfrastruktureinrichtungen-mit-uberregionaler-bedeutung/</a></p>
<p>DINI-AG-KIM (2013): LOD-Glossar. Online: <a href="https://github.com/dini-ag-kim/publications/blob/f781263297e6f1f4acdd8b2256686c0437d047bb/glossar.md">https://github.com/dini-ag-kim/publications/blob/f781263297e6f1f4acdd8b2256686c0437d047bb/glossar.md</a></p>
<p>Christof, Jürgen; Wonke-Stehle, Jens (2012): 101. Bibliothekartag 2012. Virtuelle Fachbibliotheken - Bilanz und Ausblick . Online: <a href="http://www.slideshare.net/jensws/virtuelle-fachbibliotheken-bilanz-und-ausblick">http://www.slideshare.net/jensws/virtuelle-fachbibliotheken-bilanz-und-ausblick</a></p>
<p>Depping, Ralf (2012): 101. Bibliothekartag 2012 . Sondersammelgebiete im elektronischen Zeitalter. Online: <a href="http://www.slideshare.net/vascoda/sondersammelgebiete-im-elektronischen-zeitalter">http://www.slideshare.net/vascoda/sondersammelgebiete-im-elektronischen-zeitalter</a></p>
<p>DINI-AG-KIM (2013): Empfehlung für die RDF-Repräsentation bibliografischer Daten. Online: <a href="https://wiki.dnb.de/pages/viewpage.action?pageId=68060017">https://wiki.dnb.de/pages/viewpage.action?pageId=68060017</a></p>
<p>Berners-Lee, Tim (2009): On the next web. Online: <a href="http://www.ted.com/talks/tim_berners_lee_on_the_next_web.html">http://www.ted.com/talks/tim_berners_lee_on_the_next_web.html</a></p>
<p>Christoph, Pascal (2013): Datenanreicherung auf LOD-Basis. Online: <a href="http://www.dr0i.de/lib/pages/Datenanreicherung_auf_LOD_Basis.html">http://www.dr0i.de/lib/pages/Datenanreicherung_auf_LOD_Basis.html</a></p>
<p>Diverse (2013): Massively-Multiplayer_Online_Bibliography. <a href="https://meta.wikimedia.org/wiki/Massively-Multiplayer_Online_Bibliography">https://meta.wikimedia.org/wiki/Massively-Multiplayer_Online_Bibliography</a></p>
<p>Governor, James (2007): Why Applications Are Like Fish and Data is Like Wine. Online: <a href="http://redmonk.com/jgovernor/2007/04/05/why-applications-are-like-fish-and-data-is-like-wine/">http://redmonk.com/jgovernor/2007/04/05/why-applications-are-like-fish-and-data-is-like-wine/</a></p>
<p>Kreutzer, Till (2011): Open Data – Freigabe von Daten aus Bibliothekskatalogen. Ein Leitfaden. Hg. v. Hochschulbibliothekszentrum des Landes Nordrhein-Westfalen. URL: <a href="http://www.hbz-nrw.de/dokumentencenter/veroeffentlichungen/open-data-leitfaden.pdf">http://www.hbz-nrw.de/dokumentencenter/veroeffentlichungen/open-data-leitfaden.pdf</a></p>
<p>Pohl, Adrian (2013): Mit der DFG und CIB nach WorldShare und Alma. Online: <a href="http://www.uebertext.org/2013/04/mit-der-dfg-und-cib-nach-wordshare-und.html">http://www.uebertext.org/2013/04/mit-der-dfg-und-cib-nach-wordshare-und.html</a></p>
<p>Weaver, Jesse; Tarjan, Paul (2012): Facebook Linked Data via the Graph API. <a href="http://www.semantic-web-journal.net/content/facebook-linked-data-graph-api">http://www.semantic-web-journal.net/content/facebook-linked-data-graph-api</a></p>
<p>Graf, Klaus (2013): Schlechte Bücher? Publikationsmöglichkeiten im 21. Jahrhundert als Herausforderung für Bibliotheken <a href="http://archiv.twoday.net/stories/472713645/">http://archiv.twoday.net/stories/472713645/</a></p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Siehe dazu auch die 10 Thesen Tochtermanns (2013) <a href="http://www.zbw-mediatalk.eu/2013/08/klaus-tochtermann-zehn-thesen-zum-zukunftigen-profil-von-wissenschaftlichen-informationsinfrastruktureinrichtungen-mit-uberregionaler-bedeutung/">&quot;10 Thesen zum zukünftigen Profil von wissenschaftlichen Informations-Infrastruktureinrichtungen mit überregionaler Bedeutung&quot;</a>. Der in Tochtermanns Thesen verwendete Begriff des &quot;Semantic Web&quot; ist synonym zu &quot;Linked Data&quot; verwendet.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Es ist dennoch zu betonen, dass es auch eine große Auswahl an proprietären Softwarelösungen gibt - insbesondere bei sogenannten &quot;Triple Stores&quot; oder Graphdatenbanken.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>zitiert nach Tim Berners Lee, 1999: <a href="http://lists.w3.org/Archives/Public/www-rdf-interest/1999Dec/0113.html">http://lists.w3.org/Archives/Public/www-rdf-interest/1999Dec/0113.html</a><a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>Berners-Lee ist ein britischer Physiker und Informatiker, Erfinder von HTML und Begründer des WWW, siehe <a href="https://de.wikipedia.org/wiki/Tim_Berners_Lee">https://de.wikipedia.org/wiki/Tim_Berners_Lee</a><a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>D. h. es wird eine Lizenz verwendet, die kompatibel ist mit der <a href="http://opendefinition.org/">Open Definition</a>. Für eine Definition von offenen <em>bibliographischen</em> Daten siehe die &quot;Prinzipien zu offenen bibliographischen Daten&quot; unter <a href="http://openbiblio.net/principles/de/">http://openbiblio.net/principles/de/</a>. Ein umfangreicher rechtlicher Ratgeber zur Freigabe von Daten aus Bibliothekskatalogen ist.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>Für eine Übersicht über offene Datensets im internationalen Bibliothekskontext siehe die Gruppe &quot;Bibliographic Data&quot; im Open-Data-Verzeichnis &quot;The Data Hub&quot;: <a href="http://datahub.io/group/bibliographic">http://datahub.io/group/bibliographic</a> .<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>Siehe dazu z.B. Graf, Klaus: <a href="[http://archiv.twoday.net/stories/472713645/](http://archiv.twoday.net/stories/472713645/">Schlechte Bücher? Publikationsmöglichkeiten im 21. Jahrhundert als Herausforderung für Bibliotheken. 2013.</a><a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>Z. B. durch RDFa in HTML oder XMP in PDF/A<a href="#fnref8">↩</a></p></li>
<li id="fn9"><p>Auf diese Weise ließe sich auch recht einfach aussagekräftigere Metriken berechnen: Wie oft wurde Artikel A referenziert und mit welcher Absicht (Widerspruch/Kritik, Zustimmung)? Wie oft wurden die Artikel, die Artikel A referenzieren, referenziert? Mit welchen Schlagworten sind die Ressourcen versehen? Usw.<a href="#fnref9">↩</a></p></li>
<li id="fn10"><p>Da die Daten global verfügbar sind wird zukünftig immer weniger redundant mehrfachkatalogisiert. Die Arbeit wird aber nicht weniger, sondern verlagert sich in Richtung Moderation und Selektion von Daten aus dem &quot;web of data&quot;.<a href="#fnref10">↩</a></p></li>
<li id="fn11"><p>bei MAB2 und MARC sind das 9999 Bytes<a href="#fnref11">↩</a></p></li>
<li id="fn12"><p>Wenn ein Datensatz dadurch größer als 9999 Bytes wird, so stellt dies, anders als bei MARC/MAB, kein Problem dar. Tatsächlich ist die Größe eines Datensatzes beliebig.<a href="#fnref12">↩</a></p></li>
<li id="fn13"><p>Der Weg dahin wurde bereits eingeschlagen, siehe <a href="https://github.com/dbpedia/dbpedia-links/">https://github.com/dbpedia/dbpedia-links/</a><a href="#fnref13">↩</a></p></li>
<li id="fn14"><p>siehe dazu auch <a href="http://www.dr0i.de/lib/pages/Datenanreicherung_auf_LOD_Basis.html">&quot;Datenanreicherung auf LOD-Basis&quot;</a><a href="#fnref14">↩</a></p></li>
<li id="fn15"><p>Das ist eine krude Methode, um aus einfachen, nicht extra zur Datenextraktion hergestellten HTML-Seiten strukturierte Daten zu gewinnen. Da der Aufbau von Webseiten sich ändern kann ist diese Technik instabil und von deren Einsatz abzuraten.<a href="#fnref15">↩</a></p></li>
<li id="fn16"><p>Wer das Manifest mit weiterentwickeln möchte, kann dies leicht auf einem Etherpad tun unter <a href="http://etherpad.lobid.org/p/LEM">http://etherpad.lobid.org/p/LEM</a>.<a href="#fnref16">↩</a></p></li>
<li id="fn17"><p>Ein Beispiel zur Überführung der ZDB-ISIL Datei in LOD ist: <a href="https://github.com/lobid/lodmill/blob/master/lodmill-rd/src/main/resources/morph_zdb-isil-file-pica2ld.xml">https://github.com/lobid/lodmill/blob/master/lodmill-rd/src/main/resources/morph_zdb-isil-file-pica2ld.xml</a>.<a href="#fnref17">↩</a></p></li>
<li id="fn18"><p>Ein Beispiel dieser sog. flux-Datei ist: <a href="https://github.com/lobid/lodmill/blob/master/lodmill-rd/src/main/resources/zdb-isil-file2lobid-organisation.flux">https://github.com/lobid/lodmill/blob/master/lodmill-rd/src/main/resources/zdb-isil-file2lobid-organisation.flux</a>.<a href="#fnref18">↩</a></p></li>
<li id="fn19"><p>Sollte einmal eine Funktionalität fehlen, so sind die Module einfach zu programmieren und der Software zufügbar. So entstanden bisher viele Module, z.B. für das Einlesen von csv,xml,ntriples und konkreter dann Pica/MAB/MARC/LOD über verschiedene Quellen wie Dateien im Filesystem, Webseiten, OAI-PMH usw.<a href="#fnref19">↩</a></p></li>
<li id="fn20"><p>Eine API ist eine Programmierschnittstelle, die es ermöglicht, von einem Softwaresystem auf ein anderes zuzugreifen. Bei einer Web-API geschieht dies über das WWW, siehe <a href="https://en.wikipedia.org/wiki/Web_API">https://en.wikipedia.org/wiki/Web_API</a>.<a href="#fnref20">↩</a></p></li>
<li id="fn21"><p>Siehe <a href="http://api.lobid.org/">http://api.lobid.org/</a><a href="#fnref21">↩</a></p></li>
<li id="fn22"><p>also dem Einsatz von freiwilligen Benutzern<a href="#fnref22">↩</a></p></li>
<li id="fn23"><p>Beispiele von funktionierendem Crowdsourcing sind u.a. Wikipedia, Amazon, IMDB. Früher war z.B. auch dmoz recht beliebt. Bei dmoz werden Internetquellen intellektuell erschlossen. In Hochzeiten hatte dieser Dienst mehrere 10.000 aktive freiwillige Mitarbeiter. Bis jetzt sind 4.8 Millionen Seiten katalogisiert. Seit Gründung 1998 sind die erzeugten Daten offen und können so von anderen Diensten übernommen werden. Google hat die Daten bis 2011 genutzt.<a href="#fnref23">↩</a></p></li>
<li id="fn24"><p>Siehe <a href="https://de.wikipedia.org/wiki/Wikidata">https://de.wikipedia.org/wiki/Wikidata</a><a href="#fnref24">↩</a></p></li>
<li id="fn25"><p>Dieselbe Stiftung hat mit der <a href="https://meta.wikimedia.org/wiki/Massively-Multiplayer_Online_Bibliography">&quot;Massively-Multiplayer_Online_Bibliography&quot;</a> eine recht neue Projektidee, in der es darum geht, mit Hilfe Freiwilliger (der &quot;Crowd&quot;) Millionen von frei verfügbaren Essays und Artikeln usw. nach LOD Prinzipien zu annotieren. Auch wenn dieses Projekt vielleicht gar nicht starten wird oder auch, wenn es dabei bleibt, nur nicht-akademische, nicht-fiktionale Texte zu katalogisieren, so ist dieses Projekt doch eine interessante Blaupause für ein Modell, wie graue akademische Literatur gesammelt werden kann. In dieses Projektmodell passen nämlich hervorragend Bibliothekare oder eben FIDs mit ihrem Wissen. Sie können z.B. dabei helfen, Taxonomien für die Texte bereitzustellen oder, bei fehlenden Taxonomien, diese Erstellen. Andere Menschen in dem Projekt werden Katalogisierungswerkzeuge zur Verfügung stellen, in denen diese Taxonomien eingebunden sind, sodass sie vom Katalogisierer (der &quot;Crowd&quot;) per Drop-Down-Menü und durch multilinguale Vorschlagssuchen kategorisiert werden können. Danach können die so kategorisierten Ressourcen automatisch gefiltert und die Metadaten automatisch an den jeweiligen FID gesendet werden, um sie der fachspezifischen Sammlung nach einem Moderationsprozess hinzuzufügen. Diese Information, also das Kategorisieren einer Ressource zu einem FID, ist wiederum eine interessante, aussagekräftiges Information, die der ursprünglichen Ressourcenbeschreibung zugefügt wird. Somit fließt die moderierende, qualitätssichernde Kontrolle der Fachprofis in die Ausgangsdaten zurück und sind von allen anderen, die diese Daten konsumieren, nachnutzbar. Im LOD Paradigma erzeugt also die Nutzung einer Leistung potentiell einen Mehrwert für die Leistung. Es handelt sich um eine sog. Selbstverstärkung.<a href="#fnref25">↩</a></p></li>
<li id="fn26"><p>Softwareentwickler nennen dieses Verfahren das &quot;Model-View-Controller&quot; (MVC) Prinzip.<a href="#fnref26">↩</a></p></li>
<li id="fn27"><p>Siehe http://www.uebertext.org/2013/04/mit-der-dfg-und-cib-nach-wordshare-und.html <a href="#fnref27">↩</a></p></li>
<li id="fn28"><p>Siehe http://dfg.de/foerderung/info_wissenschaft/archiv/2013/info_wissenschaft_13_11/index.html<a href="#fnref28">↩</a></p></li>
<li id="fn29"><p>Siehe http://openbiblio.net/2011/08/11/ex-libris-alma-and-open-data/<a href="#fnref29">↩</a></p></li>
<li id="fn30"><p>Siehe dazu z.B. <a href="https://en.wikipedia.org/wiki/Schema.org">Schema.org</a>, dass von den großen Internetsuchmaschinenbetreibern initiiert wurde, um die Webseiten für (Such-)Maschinen mittels Linked Data besser verstehbar zu machen. Einige ViFas haben schon begonnen, Schema.org in ihre Portale zu integrieren, z.B. <a href="http://edoc.vifapol.de">http://edoc.vifapol.de</a>. <a href="http://linkeddata.econstor.eu/">Econstor</a>, ein Dokumentenserver der ViFas, bietet aus diesem Grund schon seit geraumer Zeit Linked Data an.<a href="#fnref30">↩</a></p></li>
</ol>
</div>
